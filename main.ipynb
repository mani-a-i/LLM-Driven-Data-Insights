{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5a66c5-e77d-4b6a-a015-eec12147c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig\n",
    "# from optimum.gptq import GPTQQuantizer, load_quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d435ecd-ea7b-4832-811f-cf3ecd3d0517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mgpu-server         \u001b[m  Mon Feb  5 10:44:00 2024  \u001b[1m\u001b[30m495.29.05\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mQuadro RTX 5000 \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   17\u001b[m / \u001b[33m16122\u001b[m MB | \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m9M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m3M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0046508f-ba98-43e7-9ee2-0ec8f2f4319d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_to_use = 0\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(f'cuda:{gpu_to_use}' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a7e2d6-be02-453e-93cc-3f17a110f032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\",load_in_4bit = True\n",
    "    # trust_remote_code=True,\n",
    "    # cache_dir  = './tokenizer'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245ab124-832a-45aa-b7b9-112a375c7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\",load_in_4bit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "482420c7-e7a0-4bc5-abd2-f17dbb584991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(prompt):\n",
    "    toks = tokenizer(prompt,return_tensors = 'pt').to(device)\n",
    "    output = model.generate(\n",
    "        **toks,\n",
    "        top_k = 1,\n",
    "        do_sample = True,\n",
    "        temperature = 0.2,\n",
    "        max_new_tokens = 200,\n",
    "        eos_token_id = [10897,63,4686,10252],\n",
    "    )\n",
    "    output = output[0][len(toks.input_ids[0]):]\n",
    "    output = tokenizer.decode(output)\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd763982-f3f6-47f2-9bc9-e3ea3719a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# You're a highly skilled Python coder known for your mastery in pandas,seaborn,matplotlib,plotly.\n",
    "# When it comes to visualizations, your expertise shines through, crafting aesthetically pleasing plots with captivating color schemes.\n",
    "# Always import necessary libraries and load the dataset.\n",
    "# ### Rules:\n",
    "# 1) print values above the bars of bar plot.\n",
    "# 2) the output should be phrased with respect to question.\n",
    "# 3) Use seaborn or plotly along with matplotlib\n",
    "# 4) do not print values above the bar if it gets too congested\n",
    "# 5) only give the code without explanation.\n",
    "\n",
    "# 6) I want you to generate what is asked, if i told you to read csv file the output should be:\n",
    "#     import pandas as pd\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "#     import numpy as np            \n",
    "#     df = pd.read_csv('Salaries.csv')\n",
    "#     instead of :\n",
    "#     import pandas as pd\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "#     import numpy as np\n",
    "    \n",
    "#     df = pd.read_csv('Salaries.csv')\n",
    "    \n",
    "#     # ln[10]:\n",
    "#      python\n",
    "#     plt.figure(figsize=(10,6))\n",
    "#     sns.barplot(x='rank', y='salary', hue='discipline', data=df, palette='viridis')\n",
    "# Generate what is asked, do not give extra output.\n",
    "\n",
    "\n",
    "# You should strictly follow the above rule\n",
    "\n",
    "# Here's the scoop on the \"Salaries.csv\" dataset, boasting 78 records featuring diverse columns:\n",
    "\n",
    "\n",
    "# |   | rank | discipline | phd | service |  sex  | salary |\n",
    "# |---|------|------------|-----|---------|-------|--------|\n",
    "# | 0 | Prof |     B      | 56  |   49    | Male  | 186960 |\n",
    "# | 1 | Prof |     A      | 12  |    6    | Male  |  93000 |\n",
    "# | 2 | Prof |     A      | 23  |   20    | Male  | 110515 |\n",
    "# | 3 | Prof |     A      | 40  |   31    | Male  | 131205 |\n",
    "# | 4 | Prof |     B      | 20  |   18    | Male  | 104800 |\n",
    "\n",
    " \n",
    "# ## majnu: {}\n",
    "# ## Basha:\n",
    "\n",
    "# # ln[3]:\n",
    "# ``` python\n",
    "# \"\"\"\n",
    "\n",
    "# nl_prompt =  prompt.format(\"create a bar plot for number of males and females\")\n",
    "# # nl_prompt =  prompt.format(\"Write a code to load a dataset\")\n",
    "# # print(f'prompt: {nl_prompt}')\n",
    "# # print('-'*100)\n",
    "# out = gen(nl_prompt).replace(\"```\",\"\")\n",
    "# print(out)\n",
    "# # print('-'*100)\n",
    "# # exec(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "644b69a8-3fa0-49a8-9e69-8e7f42be1826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:10897 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pivot_table = df.pivot_table(values='salary', index='discipline', columns='sex', aggfunc='mean')\n",
      "pivot_table.plot(kind='bar', stacked=True)\n",
      "plt.title('Average Salaries by Discipline and Gender')\n",
      "plt.xlabel('Discipline')\n",
      "plt.ylabel('Average Salary')\n",
      "plt.legend(title='Sex', loc='upper left')\n",
      "plt.show()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You're a highly skilled Python coder known for your mastery in pandas, seaborn, matplotlib, plotly.\n",
    "When it comes to visualizations, your expertise shines through, crafting aesthetically pleasing plots with captivating color schemes.\n",
    "Always import necessary libraries and load the dataset.\n",
    "\n",
    "### Rules:\n",
    "1) print values above the bars of bar plot.\n",
    "2) the output should be phrased with respect to question.\n",
    "3) Use seaborn or plotly along with matplotlib\n",
    "4) do not print values above the bar if it gets too congested\n",
    "5) only give the code without explanation and comments.\n",
    "\n",
    "# You should strictly follow the above rule\n",
    "\n",
    "Here's the scoop on the \"Salaries.csv\" dataset, boasting 78 records featuring diverse columns:\n",
    "\n",
    "|   | rank | discipline | phd | service |  sex  | salary |\n",
    "|---|------|------------|-----|---------|-------|--------|\n",
    "| 0 | Prof |     B      | 56  |   49    | Male  | 186960 |\n",
    "| 1 | Prof |     A      | 12  |    6    | Male  |  93000 |\n",
    "| 2 | Prof |     A      | 23  |   20    | Male  | 110515 |\n",
    "| 3 | Prof |     A      | 40  |   31    | Male  | 131205 |\n",
    "| 4 | Prof |     B      | 20  |   18    | Male  | 104800 |\n",
    "\n",
    "# Follow the example below\n",
    "User: Give me salary distribution across all sex\n",
    "Assistant: \n",
    "df = pd.read_csv(\"Salaries.csv\")\n",
    "salary_distribution = df.groupby('sex')['salary'].mean()\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "salary_distribution.plot(kind='bar', color=colors)\n",
    "plt.title('Salary Distribution Across Sexes')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Average Salary')\n",
    "plt.show()\n",
    "\n",
    "# Assist user\n",
    "\n",
    "User: {}\n",
    "Assistant:\n",
    "```python\n",
    "df = pd.read_csv(\"Salaries.csv\")\"\"\"\n",
    "\n",
    "nl_prompt =  prompt.format(\"for each gender and discipline plot average salaries\")\n",
    "# nl_prompt =  prompt.format(\"Write a code to load a dataset\")\n",
    "# print(f'prompt: {nl_prompt}')\n",
    "# print('-'*100)\n",
    "out = gen(nl_prompt)\n",
    "print(out)\n",
    "# print('-'*100)\n",
    "# exec(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8053cd4a-f890-4bcd-a553-750a1859d777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10897"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3e35758-edb4-4d30-9f87-4d67ab435982",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59040e0-d596-4788-964d-aed1238bdecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mayur2",
   "language": "python",
   "name": "mayur2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
